{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [**一、数据处理部分**](#step1)\n",
    "- [**1. 原始json文件转换为csv文件**](#step11) \t\n",
    "\n",
    "- [**2. 滤波（中值、低通）**](#step12) \n",
    "\n",
    "- [**3. 分离人体/重力加速度**](#step13) \n",
    "\n",
    "- [**4. 提取特征**](#step14) \n",
    "\n",
    "- [**5. 训练模型**](#step14) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 原始json文件转换为csv文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "动作1： 22 动作2： 19 动作3： 18 动作4： 18\n",
      "拥有样本数： 77\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 创建文件对象\n",
    "new_activity = open(\"./raw_csv/new_activity.csv\", 'w', encoding='utf-8', newline='')\n",
    "# 2. 基于文件对象构建 csv写入对象\n",
    "csv_writer = csv.writer(new_activity)\n",
    "# 3. 构建列表头\n",
    "csv_writer.writerow([\"accx\", \"accy\", \"accz\", \"gryx\", \"gryy\", \"gryz\", \"number\", \"activity\"])\n",
    "\n",
    "record = 0      # 拥有的动作记录总数\n",
    "a1 = 0\n",
    "with open(\"./raw_json/activity1.json\", 'r', encoding=\"utf-8\") as f:\n",
    "    for jsonstr in f.readlines():\n",
    "        dict_json = json.loads(jsonstr)\n",
    "        if (dict_json['accx'] != [] and dict_json['accy'] != [] and dict_json['accz'] != [] and\n",
    "            dict_json['gryx'] != [] and dict_json['gryy'] != [] and dict_json['gryz'] != []):\n",
    "            record += 1\n",
    "            a1 += 1\n",
    "            for i in range(20, 70):\n",
    "                csv_writer.writerow([dict_json['accx'][i], dict_json['accy'][i], dict_json['accz'][i], dict_json['gryx'][i], dict_json['gryy'][i], dict_json['gryz'][i], dict_json['number'], '1'])\n",
    "\n",
    "a2 = 0\n",
    "with open(\"./raw_json/activity2.json\", 'r', encoding=\"utf-8\") as f:\n",
    "    for jsonstr in f.readlines():\n",
    "        dict_json = json.loads(jsonstr)\n",
    "        if (dict_json['accx'] != [] and dict_json['accy'] != [] and dict_json['accz'] != [] and\n",
    "            dict_json['gryx'] != [] and dict_json['gryy'] != [] and dict_json['gryz'] != []):\n",
    "            record += 1\n",
    "            a2 += 1\n",
    "            for i in range(20, 70):\n",
    "                csv_writer.writerow([dict_json['accx'][i], dict_json['accy'][i], dict_json['accz'][i], dict_json['gryx'][i], dict_json['gryy'][i], dict_json['gryz'][i], dict_json['number'], '2'])\n",
    "\n",
    "a3 = 0\n",
    "with open(\"./raw_json/activity3.json\", 'r', encoding=\"utf-8\") as f:\n",
    "    for jsonstr in f.readlines():\n",
    "        dict_json = json.loads(jsonstr)\n",
    "        if (dict_json['accx'] != [] and dict_json['accy'] != [] and dict_json['accz'] != [] and\n",
    "            dict_json['gryx'] != [] and dict_json['gryy'] != [] and dict_json['gryz'] != []):\n",
    "            record += 1\n",
    "            a3 += 1\n",
    "            for i in range(20, 70):\n",
    "                csv_writer.writerow([dict_json['accx'][i], dict_json['accy'][i], dict_json['accz'][i], dict_json['gryx'][i], dict_json['gryy'][i], dict_json['gryz'][i], dict_json['number'], '3'])\n",
    "\n",
    "a4 = 0\n",
    "with open(\"./raw_json/activity4.json\", 'r', encoding=\"utf-8\") as f:\n",
    "    for jsonstr in f.readlines():\n",
    "        dict_json = json.loads(jsonstr)\n",
    "        if (dict_json['accx'] != [] and dict_json['accy'] != [] and dict_json['accz'] != [] and\n",
    "            dict_json['gryx'] != [] and dict_json['gryy'] != [] and dict_json['gryz'] != []):\n",
    "            record += 1\n",
    "            a4 += 1\n",
    "            for i in range(20, 70):\n",
    "                csv_writer.writerow([dict_json['accx'][i], dict_json['accy'][i], dict_json['accz'][i], dict_json['gryx'][i], dict_json['gryy'][i], dict_json['gryz'][i], dict_json['number'], '4'])\n",
    "\n",
    "print(\"动作1：\", a1, \"动作2：\", a2, \"动作3：\", a3, \"动作4：\", a4)\n",
    "print(\"拥有样本数：\", record)\n",
    "new_activity.close() \n",
    "\n",
    "plt.bar([1, 2, 3, 4], [a1, a2, a3, a4], label='动作数')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 滤波（中值、低通） + 分离人体/重力加速度\n",
    "### 3. 提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2         3         4         5     6  \\\n",
      "0  -0.027955  0.027992  0.167309 -0.319466  0.186107 -0.319466  17.0   \n",
      "1   0.023147  0.023230  0.152414 -0.252696  0.250503 -0.252696  21.0   \n",
      "2   0.049697  0.037356  0.193277 -0.252696  0.328154 -0.252696  12.0   \n",
      "0   0.035426  0.115473  0.339813 -0.611118  0.481536 -0.611118  20.0   \n",
      "1   0.108641  0.129192  0.359432 -0.665126  0.574245 -0.665126  21.0   \n",
      "..       ...       ...       ...       ...       ...       ...   ...   \n",
      "1  -0.036863  0.047951  0.218978 -0.358327  0.456734 -0.358327  10.0   \n",
      "2   0.002047  0.053210  0.230674 -0.224993  0.496661 -0.224993   5.0   \n",
      "0   0.036956  0.095112  0.308403 -0.440334  0.634951 -0.440334  13.0   \n",
      "1  -0.022617  0.046672  0.216037 -0.413439  0.353834 -0.413439  13.0   \n",
      "2  -0.065700  0.028051  0.167485 -0.355529  0.245555 -0.355529   6.0   \n",
      "\n",
      "           7         8         9  ...        14        15        16        17  \\\n",
      "0   0.505573  0.229558  5.924744  ...  0.095329  0.005714  0.075591  0.763934   \n",
      "1   0.503199  0.096320  8.785003  ...  0.049335  0.002011  0.044844  0.738309   \n",
      "2   0.580851  0.240983  3.272845  ...  0.208872  0.003829  0.061880 -0.439153   \n",
      "0   1.092654  0.067969  9.193130  ...  0.892596  0.164522  0.405613 -0.133544   \n",
      "1   1.239371  0.305921  8.275082  ...  0.600137  0.541039  0.735554  1.101073   \n",
      "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
      "1   0.815062  0.314930  7.034169  ...  0.208999  0.017006  0.130407  0.550364   \n",
      "2   0.721654  0.080759  4.244988  ...  0.064954  0.000735  0.027106 -0.868449   \n",
      "0   1.075285  0.634951  5.508735  ...  0.263647  0.019637  0.140131 -0.246020   \n",
      "1   0.767273  0.179498  7.345773  ...  0.415635  0.035130  0.187431  0.077031   \n",
      "2   0.601084  0.115862  3.474953  ...  0.251286  0.013919  0.117980 -0.197811   \n",
      "\n",
      "          18     gra_x     gra_y     gra_z  number  activity  \n",
      "0   0.028300  0.384583  0.743926  0.519461       1         1  \n",
      "1  -1.116575  0.384583  0.743926  0.519461       1         1  \n",
      "2  -1.159821  0.384583  0.743926  0.519461       1         1  \n",
      "0  -0.745527  0.343761 -0.716602  0.479363       1         1  \n",
      "1  -0.449214  0.343761 -0.716602  0.479363       1         1  \n",
      "..       ...       ...       ...       ...     ...       ...  \n",
      "1  -0.605662  0.965846 -0.179310 -0.112335       2         4  \n",
      "2   0.227020  0.965846 -0.179310 -0.112335       2         4  \n",
      "0  -0.831062  0.156797 -0.080964  0.866034       3         4  \n",
      "1  -0.755924  0.156797 -0.080964  0.866034       3         4  \n",
      "2  -1.023266  0.156797 -0.080964  0.866034       3         4  \n",
      "\n",
      "[231 rows x 119 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from filter import filter_func, components_selection_one_signal\n",
    "# 提取特征\n",
    "from extract_feature import feature_core\n",
    "\n",
    "# 把所有动作记录存入同一个字典\n",
    "all_data = pd.read_csv(\"./raw_csv/new_activity.csv\")\n",
    "raw_dic = {}\n",
    "for i in range(0, 77):\n",
    "    data = all_data.loc[i*50:i*50+49, :]        # 3s: 50个数据\n",
    "    data = pd.DataFrame(data)\n",
    "    key = i+1\n",
    "    raw_dic[key] = data\n",
    "\n",
    "\n",
    "# 建立新dic（分离了人体、重力）\n",
    "new_dic = {}\n",
    "new_columns = ['t_body_accx', 't_body_accy', 't_body_accz',   # 10个分量\n",
    "                       't_grav_accx', 't_grav_accy', 't_grav_accz',\n",
    "                       't_body_gryx', 't_body_gryy', 't_body_gryz', 'number', 'activity']\n",
    "for key in range(1, 78):\n",
    "    raw_df = raw_dic[key]\n",
    "    time_sig_df = pd.DataFrame()  # 每条记录一个新DataFrame\n",
    "\n",
    "    for column in raw_df.columns:  # 旧列名\n",
    "        # 遍历每一列\n",
    "        t_signal = np.array(raw_df[column])\n",
    "        med_filtred = filter_func(t_signal)\n",
    "        if 'acc' in column:  # acc列(x,y,z)\n",
    "            _, grav_acc, body_acc, _ = components_selection_one_signal(med_filtred)\n",
    "            time_sig_df['t_body_' + column] = body_acc[:]\n",
    "            time_sig_df['t_grav_' + column] = grav_acc[:]\n",
    "\n",
    "        elif 'gry' in column:  # gry列(x,y,z)\n",
    "            _,_,body_gyro,_=components_selection_one_signal(med_filtred)\n",
    "            time_sig_df['t_body_'+column] = body_gyro[:]\n",
    "\n",
    "    time_sig_df['number'] = np.array(raw_df['number'])    # 次数\n",
    "    time_sig_df['activity'] = np.array(raw_df['activity'])  # 次数\n",
    "    t_signal = np.array(raw_df['number'])\n",
    "    ordered_time_sig_df = pd.DataFrame()\n",
    "    for col in new_columns:\n",
    "        ordered_time_sig_df[col] = time_sig_df[col]\n",
    "\n",
    "    new_dic[key] = ordered_time_sig_df\n",
    "\n",
    "\n",
    "# 提取特征\n",
    "all_feature = pd.DataFrame()\n",
    "for i in range(1, 78):\n",
    "    feature_ = pd.DataFrame()\n",
    "    for j in [0, 1, 2, 6, 7, 8]:\n",
    "        column = new_columns[j]\n",
    "        data = np.array(new_dic[i][column]).reshape(50, 1)\n",
    "        a = feature_core.sequence_feature(data, 32, 16)     # 19列特征  shape:(3,19)\n",
    "        data1 = pd.DataFrame(a)\n",
    "        feature_ = pd.concat([feature_, data1], axis=1)     # 横向连接19个feature\n",
    "    feature_['gra_x'] = np.full(feature_.shape[0], new_dic[i]['t_grav_accx'][0])\n",
    "    feature_['gra_y'] = np.full(feature_.shape[0], new_dic[i]['t_grav_accy'][0])\n",
    "    feature_['gra_z'] = np.full(feature_.shape[0], new_dic[i]['t_grav_accz'][0])\n",
    "    feature_['number'] = np.full(feature_.shape[0], int(new_dic[i]['number'][0]/5))\n",
    "    feature_['activity'] = np.full(feature_.shape[0], new_dic[i]['activity'][0])\n",
    "    all_feature = pd.concat([all_feature, feature_], axis=0)     # 纵向连接不同记录\n",
    "print(all_feature)\n",
    "\n",
    "\n",
    "all_feature.to_csv(\"./extract_feature/feature.csv\", index=False,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.随机森林训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02314718  0.02322992  0.15241364 ...  0.51946064  1.\n",
      "   1.        ]\n",
      " [ 0.04969742  0.03735613  0.19327733 ...  0.51946064  1.\n",
      "   1.        ]\n",
      " [ 0.03542649  0.1154732   0.33981348 ...  0.47936284  1.\n",
      "   1.        ]\n",
      " ...\n",
      " [ 0.03695613  0.09511212  0.30840253 ...  0.86603427  3.\n",
      "   4.        ]\n",
      " [-0.02261711  0.04667208  0.21603721 ...  0.86603427  3.\n",
      "   4.        ]\n",
      " [-0.06569979  0.0280512   0.16748491 ...  0.86603427  3.\n",
      "   4.        ]]\n",
      "0.9130434782608695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./forest.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 训练\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split     # 将数据分为测试集和训练集\n",
    "import joblib\n",
    "np.random.seed(100)\n",
    "\n",
    "all_feature = pd.read_csv(\"./extract_feature/feature.csv\")\n",
    "all_feature = np.array(all_feature)\n",
    "print(all_feature)\n",
    "\n",
    "# 利用train_test_split进行将训练集和测试集进行分开，test_size占30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_feature[:, :-2], all_feature[:, -1], test_size=0.3)  \n",
    "rfc = RandomForestClassifier()  # 实例化\n",
    "rfc = rfc.fit(X_train, y_train)  # 用训练集数据训练模型\n",
    "result = rfc.score(X_test, y_test)\n",
    "print(result)\n",
    "\n",
    "joblib.dump(rfc, \"./forest.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}